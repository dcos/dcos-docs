---
post_title: Local Volumes 
menu_order: 1
---

#  Local Volumes Using Mount Disk Resources

Mesos Volume Mounts give services the ability to reserve dedicated disk space throughout the cluster. This is particularly useful for stateful services like Kafka and Cassandra.

In DC/OS it is possible to configure [Mesos Mount disk resources][1] across the cluster by simply mounting storage resources on Agents using a well-known path. When a DC/OS agent starts for the first time it will scan for volumes matching the pattern `/dcos/volumeN`, where N is an integer, and automatically configure the Mesos Agent to offer these disk resources to other services.

## Example using loopback device

The example below shows how to add a disk resource to a DC/OS agent post-install on a running cluster. The same steps can be used pre-install, but in that scenario it is not necessary to stop services or clear the Mesos Agent state.

***Warning:*** This will terminate any running tasks or services on the node.

1. Connect to an agent in the cluster with SSH

2. Examine the current Mesos Agent resource state

  Note there are no references yet for `/dcos/volume0`.

  ```bash
  $ cat /var/lib/dcos/mesos-resources
  # Generated by make_disk_resources.py on 2016-05-05 17:04:29.868595
  #

  MESOS_RESOURCES='[{"ranges": {"range": [{"end": 21, "begin": 1}, {"end": 5050, "begin": 23}, {"end": 32000, "begin": 5052}]}, "type": "RANGES", "name": "ports"}, {"role": "*", "type": "SCALAR", "name": "disk", "scalar": {"value": 47540}}]'
  ```

3. Stop the Mesos Agent

  On a Private Agent:

  ```bash
  $ sudo systemctl stop dcos-mesos-slave.service
  ```

  On a Public Agent:

  ```bash
  $ sudo systemctl stop dcos-mesos-slave-public.service
  ```

4. Clear Mesos Agent state

  Remove Volume Mount Discovery resource state

  ```bash
  $ sudo rm -f /var/lib/dcos/mesos-resources
  ```

  Remove Mesos Agent checkpoint state

  ```bash
  $ sudo rm -f /var/lib/mesos/slave/meta/slaves/latest
  ```

5. Create a 200MB loopback device

  This is suitable for testing purposes only. Mount volumes must have at least 200MB of free space available. 100MB on each volume will be reserved by DC/OS and is not available for other services.

  ```bash
  $ sudo mkdir -p /dcos/volume0
  $ sudo dd if=/dev/zero of=/root/volume0.img bs=1M count=200
  $ sudo losetup /dev/loop0 /root/volume0.img
  $ sudo mkfs -t ext4 /dev/loop0
  $ sudo losetup -d /dev/loop0
  ```

6. Create fstab entry and mount

  Ensure the volume is mounted automatically at boot time. Something similar could also be done with a Systemd Mount unit.

  ```bash
  $ echo "/root/volume0.img /dcos/volume0 auto loop 0 2" | sudo tee -a /etc/fstab
  $ sudo mount /dcos/volume0
  ```

7. Reboot

  ```bash
  $ sudo reboot
  ```

8. SSH to Mesos Agent and Verify new resource state

  Look through the journald logs for references to the new volume `/dcos/volume0`. In particular, there should be an entry for the Mesos Agent starting up and the new volume0 Disk Mount resource.

  ```bash
  $ journalctl -b | grep '/dcos/volume0'
  May 05 19:18:40 dcos-agent-public-01234567000001 systemd[1]: Mounting /dcos/volume0...
  May 05 19:18:42 dcos-agent-public-01234567000001 systemd[1]: Mounted /dcos/volume0.
  May 05 19:18:46 dcos-agent-public-01234567000001 make_disk_resources.py[888]: Found matching mounts : [('/dcos/volume0', 74)]
  May 05 19:18:46 dcos-agent-public-01234567000001 make_disk_resources.py[888]: Generated disk resources map: [{'name': 'disk', 'type': 'SCALAR', 'disk': {'source': {'mount': {'root': '/dcos/volume0'}, 'type': 'MOUNT'}}, 'role': '*', 'scalar': {'value': 74}}, {'name': 'disk', 'type': 'SCALAR', 'role': '*', 'scalar': {'value': 47540}}]
  May 05 19:18:58 dcos-agent-public-01234567000001 mesos-slave[1891]: " --oversubscribed_resources_interval="15secs" --perf_duration="10secs" --perf_interval="1mins" --port="5051" --qos_correction_interval_min="0ns" --quiet="false" --recover="reconnect" --recovery_timeout="15mins" --registration_backoff_factor="1secs" --resources="[{"name": "ports", "type": "RANGES", "ranges": {"range": [{"end": 21, "begin": 1}, {"end": 5050, "begin": 23}, {"end": 32000, "begin": 5052}]}}, {"name": "disk", "type": "SCALAR", "disk": {"source": {"mount": {"root": "/dcos/volume0"}, "type": "MOUNT"}}, "role": "*", "scalar": {"value": 74}}, {"name": "disk", "type": "SCALAR", "role": "*", "scalar": {"value": 47540}}]" --revocable_cpu_low_priority="true" --sandbox_directory="/mnt/mesos/sandbox" --slave_subsystems="cpu,memory" --strict="true" --switch_user="true" --systemd_enable_support="true" --systemd_runtime_directory="/run/systemd/system" --version="false" --work_dir="/var/lib/mesos/slave"
  ```

## Cloud Provider Resources

Cloud provider storage services are typically used to back DC/OS Mount Volumes. The following reference material may be useful when desiging a production DC/OS deployment:

* [Amazon: EBS][2]
* [Azure: About disks and VHDs for Azure virtual machines][3]
* [Azure: Introduction to Microsoft Azure storage][4] (see *Blob Storage* section on Page blobs)

## Best Practices

Disk Mount Resources are primarily for stateful services like Kafka and Cassandra which can benefit from having dedicated storage available throughout the cluster. Any service utilizing a Disk Mount Resource will have exclusive access to the reserved resource. However, it is still important to take into consideration performance and reliability requirements for the service. The performance of a Disk Mount Resource is based on the characteristic of the underlying storage and DC/OS does not provide any data replication services. With this in mind:

* Use Disk Mount Resources with stateful services which have strict storage requirements.
* Carefully consider the filesystem type, storage media (network attached, SSD, etc.) and volume characteristics (RAID levels, sizing, etc.) based on the storage needs and requirements of the stateful service.
* Label Mesos Agents using a Mesos Attribute which reflects the characteristics of the Agent's Disk Mounts, e.g. IOPS200, RAID1, etc.
* Associate stateful services with storage Agents using Mesos Attribute constraints.
* Consider isolating demanding storage services to dedicated storage Agents, since the filesystem page cache is a host level shared resource.
* Ensure all services using Disk Mount Resources are designed handle the permanent loss of one or more Disk Mount Resources. Services are still responsible to manage data replication and retention, graceful recovery from failed Agents, and backups of critical service state.

[1]: http://mesos.apache.org/documentation/latest/multiple-disk/
[2]: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html
[3]: https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-about-disks-vhds/
[4]: https://azure.microsoft.com/en-us/documentation/articles/storage-introduction/
